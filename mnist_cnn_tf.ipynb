{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "2kb_UXfyARh8",
        "outputId": "4a5d7356-6734-48f6-c026-a9be6b9210bc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after function definition on line 29 (ipython-input-379905915.py, line 30)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-379905915.py\"\u001b[0;36m, line \u001b[0;32m30\u001b[0m\n\u001b[0;31m    doc = nlp(text)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 29\n"
          ]
        }
      ],
      "source": [
        "# mnist_cnn_tf.py\n",
        "\n",
        "\n",
        "# 2. One-hot not required if using sparse_categorical_crossentropy\n",
        "\n",
        "\n",
        "# 3. Build model\n",
        "model = models.Sequential([\n",
        "layers.Input(shape=(28,28,1)),\n",
        "layers.Conv2D(32, 3, activation='relu'),\n",
        "layers.Conv2D(64, 3, activation='relu'),\n",
        "layers.MaxPooling2D(pool_size=(2,2)),\n",
        "layers.Dropout(0.25),\n",
        "layers.Flatten(),\n",
        "layers.Dense(128, activation='relu'),\n",
        "layers.Dropout(0.5),\n",
        "layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "loss='sparse_categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# 4. Train\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)]\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=12, validation_split=0.1, callbacks=callbacks)\n",
        "\n",
        "\n",
        "# 5. Evaluate\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "\n",
        "# 6. Visualize predictions on 5 samples\n",
        "import matplotlib.pyplot as plt\n",
        "indices = np.random.choice(len(x_test), 5, replace=False)\n",
        "preds = model.predict(x_test[indices])\n",
        "pred_labels = np.argmax(preds, axis=1)\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(1,5, figsize=(12,3))\n",
        "for ax, img, true, pred in zip(axes, x_test[indices], y_test[indices], pred_labels):\n",
        "ax.imshow(img.squeeze(), cmap='gray')\n",
        "ax.set_title(f\"T:{true} P:{pred}\")\n",
        "ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Notes: With this architecture and ~10 epochs, expect >99% training accuracy and typically >=98-99% test accuracy.\n",
        "# To reliably exceed 95% test accuracy, ensure training runs for enough epochs and use dropout/early stopping."
      ]
    }
  ]
}